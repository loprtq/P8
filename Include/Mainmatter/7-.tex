\section{Simulation Study}
This section is based upon \citep{Hull} and \citep{Gatheral}.

To test our codes capabilities of calculating the correct risk-neutral distribution we create a simulation study. In this simulation study we want to simulate the distribution of $S_T\mid S_t$ using the Heston model. The Heston model describes how the stock price $S_t$ evolves over time depending on numerous variables, such as the stochastic volatility $V_t$. Thus, under the risk-neutral measure $\Q$ we are, on matrix form, working with the \emph{stochastic differential equations}
\begin{align}\label{Eq:EM}
    \mathrm{d}\begin{bmatrix}S_t\\V_t\end{bmatrix} &= \begin{bmatrix}rS_t\\\Psi-\lambda V_t\end{bmatrix}\,\mathrm{d}t + \begin{bmatrix}S_t\sqrt{1-\xi^2}&S_t\xi\\0&\sigma_v\sqrt{V_t}\end{bmatrix}\,\mathrm{d}\begin{bmatrix}W^{(1)}_t\\W^{(2)}_t\end{bmatrix},
\end{align}
where $W^{(1)}$ and $W^{(2)}$ are Wiener processes. Furthermore, $\lambda$ is the rate at which $V_t$ reverts to the long variance $\Psi/\lambda$, $\xi$ the correlation between the Wiener processes, and $\sigma_v$ the volatility of the stochastic volatility, $V_t$. To simulate these stochastic differential equations we use the Euler-Maruyama scheme. The Euler-Maruyama scheme numerically approximates \eqref{Eq:EM} by discretising to a partition $t=t_0<\dots<t_n=T$ for $n\in\N$. This partition is then used to define \eqref{Eq:EM} as a recursive equation given as
\begin{align*}
        \mathrm{d}\begin{bmatrix}S_{t_{k+1}}\\V_{t_{k+1}}\end{bmatrix} &= \begin{bmatrix}rS_{t_k}\\\Psi-\lambda V_{t_k}\end{bmatrix}\left(t_{k+1}-t_k\right) + \begin{bmatrix}S_{t_k}\sqrt{1-\xi^2}&S_{t_k}\xi\\0&\sigma_v\sqrt{V_{t_k}}\end{bmatrix}\begin{bmatrix}(W^{(1)}_{t_{k+1}}-W^{(1)}_{t_k})\\(W^{(2)}_{t_{k+1}}-W^{(2)}_{t_k})\end{bmatrix},\quad 0\leq k\leq n-1.
\end{align*}
For the purpose of our simulation study we set $S_t=100$, $V_t=0.2$, $\Psi=0.5$, $\lambda=0.5$, $\xi=0.7$, and $\sigma_v=0.1$ when generating prices. Being able to simulate $S_T\mid S_t$ we use Monte Carlo simulation \citep[p. 267]{Hull} to get enough data for it to be representative of the risk-neutral density. This process is repeated for each chosen time to maturity, $\tau=T-t$. 

Additionally, these stock prices are used to calculate the option price using the formula
\begin{align}
    C(t,K) &= \exp(-r\tau)\E[\Q]{(S_T-K)^+\mid S_t}.
\end{align}
In practice, we simulate $10$ million values of $S_T\mid S_t$ and determine the mean of $\max(S_T-K,0)$ using the simulated stock prices. We calculate option prices for values of $K$ and $\tau$ in the intervals $[50,250]$ and $[0.02,0.1]$, respectively, and generate a data set containing $100000$ option prices. Given these option prices, we use the formula \eqref{Eq:IV_formula} to determine the implied volatility of the options. All of this, meaning strike price, time to maturity, and implied volatility is then used as variables in the neural network. The architecture of this neural network is chosen to be the same as in \autoref{Sec.App:Calculating_Option_Prices}, with strike price and time to maturity as inputs and implied volatility as output. This neural network gives us the implied volatility surface seen in \autoref{Figures:Figures/Pictures/SynVolSurf.png}. Compared to \autoref{Figures:Figures/Pictures/Application/vol_surfaceNN.pdf}, this neural network gives a very clear volatility skew (see \autoref{Sec.Implied_Volatility}) close to maturity time instead of a smile. Additionally, compared to GOOG, this implied volatility surface is not as smooth, as it is very bumpy ITM. This bumpiness can be caused by the stochastic nature of the simulated stock prices using the Heston model, meaning that $\E[\Q]{(S_T-K)^+\mid S_t}$ varies depending on $\tau$. Thus, these bumps could cause problems later on as the surface is not smooth.

\imgfig[0.7]{Figures/Pictures/SynVolSurf.png}{Implied volatility surface generated from simulated data for $S_t=100$, strike price $K$, and time to maturity, $\tau=T-t$.}

Given the approximation of the function for implied volatility we do as in \autoref{Sec.App:RND} and determine $\frac{\partial^2}{\partial K^2}C(t,K)$. As in \autoref{Sec.App:RND} we do so using the finite difference method to determine the derivatives for the implied volatility function, and \eqref{Eq:RND_Derivatives}. Having determined all of the expressions in \eqref{Eq:RND_Derivatives}, we use $\frac{\partial^2}{\partial K^2}C(t,K)$ to determine the risk-neutral density using \eqref{Eq:App_RND}.

For $\tau\approx0.07$ this yields the density on the left hand side of \autoref{Figures:Figures/Pictures/SynDens.pdf}. Comparing this density to the one we simulated for this $\tau$ seen in the right hand side of \autoref{Figures:Figures/Pictures/SynDens.pdf}, we observe that its highest density is $0.04$ compared to $0.10$ and it has heavier tails. Both of the risk-neutral densities do, as expected, lie very close to $S_t=100$, and integrate to $1$. All of this seems to indicate that the method of approximating the risk-neutral density works fairly well, but gives much heavier tails. Moreover, it seems that even though the implied volatility surface approximated by the neural network was not very smooth it did not lead to any large errors.

\imgfig[1]{Figures/Pictures/SynDens.pdf}{Simulated risk-neutral density using Monte Carlo simulation and the Euler-Maruyama scheme (right), and calculated risk-neutral density using method described in \autoref{Sec.Calibration} (left).}

Thus, the approach we also use for the stocks, seems to work very well, even though the implied volatility points are not smooth. To test whether this density can be used to calculate the option prices, we try to do so for $100$ random points, where the option price is not $0$, as we would not be able to determine the MAPE if they are $0$. Using the same procedure as for GOOG, we thus get the real- and calculated option prices and their absolute percentage error in \autoref{Figures:Figures/Pictures/SynCalc.pdf}.

\imgfig[0.9]{Figures/Pictures/SynCalc.pdf}{Real- and calculated prices (left) and the absolute percentage error (right), when using
the ReLU function.}

What this reveals is that the procedure of determining the risk-neutral density and using it to price options can create decent results when compared to the results achieved for GOOG. The MAPE for these option prices is approximately $43\%$, where the mean error is approximately $12$. However, as is also evident in \autoref{Figures:Figures/Pictures/SynCalc.pdf}, the $100$ random option prices are not as close to $0$ as the ones for GOOG in \autoref{Figures:Figures/Pictures/APP1/realcalc_GOOG.pdf}. Thus, the relatively good $43\%$ MAPE, when comparing to the ones achieved for GOOG, could be caused by this.
 
As for GOOG we try using the sigmoid as the activation function, as it is differentiable. This gives the risk-neutral densities for $\tau\approx0.07$ seen in \autoref{Figures:Figures/Pictures/SynDensSigmoid.pdf} and the comparison of real- and calculated option prices and their percentage error seen in \autoref{Figures:Figures/Pictures/SynCalcSigmoid.pdf}. The calculated risk-neutral density in \autoref{Figures:Figures/Pictures/SynDensSigmoid.pdf} (left) is much more jagged than the risk-neutral density calculated using ReLU which is the opposite of the results we observed for GOOG. Thus, we expect this density to not perform as well when calculating the option prices.

\imgfig[1]{Figures/Pictures/SynDensSigmoid.pdf}{Simulated risk-neutral density using Monte Carlo simulation and the Euler-Maruyama scheme (right), and calculated risk-neutral density using method described in \autoref{Sec.Calibration} with the sigmoid function (left).}
\imgfig[0.9]{Figures/Pictures/SynCalcSigmoid.pdf}{Real- and calculated prices (left) and the absolute percentage error (right), when using the sigmoid function.}

The MAPE of the calculated option prices when using the sigmoid function as the activation function is approximately $49.8\%$ with an mean error of $10$, which is worse and better than the result achieved for ReLU, respectively. As already mentioned for ReLU these results can be caused by the lack of option prices close to $0$, why the large mean absolute error gives a better MAPE than the one achieved for GOOG.

Comparing \autoref{Figures:Figures/Pictures/SynDensSigmoid.pdf} and \autoref{Figures:Figures/Pictures/SynCalcSigmoid.pdf} to the ones using the ReLU activation function we observe that the MAPE in this case is especially affected by one point which has a large absolute percentage error of over $1000\%$, whereas otherwise the two seem to have similar prediction accuracy. 

Based on the results achieved for GOOG as well as in this simulation study we will be focusing on the neural network which has ReLU as the activation function in the hidden layers.

Additionally, we expect to see large error for the remainder of the other stocks, as the 100 random points used in this section where not as small as the ones used for GOOG and it thus not being directly comparable. 

as the 100 random points used this section are not as small as the ones for GOOG, the two assessments are not comparable. 